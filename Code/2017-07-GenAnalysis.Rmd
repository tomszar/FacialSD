---
title: Genetic clustering
output: 
  html_document:
    fig_height: 10
    fig_width: 10
---

In this script we will look at some descriptive statistics from the genetic PCA, previously done in Plink.
The steps to create the genetic PCA were as following:

- Remove of missing genotype data.
- LD pruning using a window size of 10kb and a VIF of 2.
- Only HapMap samples were used to create the PCA, and our samples were projected there.
- A total of 50 PCs were extracted

## Preliminaries

Calling libraries and datasets

```{r libraries datasets, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(GGally)
library(ggpubr)
library(caret)
setwd('..')
path <- getwd()
setwd(paste(path, "/Results/GenClustering", sep = ""))
pca.eigenval <- read.csv("Clus.eigenval", sep = "", header = F)
pca.eigenvec <- read.csv("Clus.eigenvec", sep = "", header = F)
PCnames      <- sprintf("PC%s",seq(1:50))
colnames(pca.eigenvec) <- c("FID", "IID", PCnames)
```

## Data cleaning

Creating a new column to plot hapmap pops against our samples more easily.

```{r new column}
pca.eigenvec$database <- pca.eigenvec$FID 
pca.eigenvec$database[!(pca.eigenvec$FID == "ASW" | pca.eigenvec$FID == "CEU" | pca.eigenvec$FID == "CHB" | pca.eigenvec$FID == "CHD" | 
                          pca.eigenvec$FID == "GIH" | pca.eigenvec$FID == "JPT" | pca.eigenvec$FID == "LWK" | pca.eigenvec$FID == "MEX" |
                          pca.eigenvec$FID == "MKK" | pca.eigenvec$FID == "TSI" | pca.eigenvec$FID == "YRI")] <- "ADAPT"
```

Because plink output is a normalized PCA, we de-normalized the PCA by multiplying the eigenvectors by the standard deviation.

```{r de-normalizing PCA}
pca.eigenvec[,3:52] <- t(c(as.matrix(pca.eigenval)) * t(as.matrix(pca.eigenvec[,3:52])))
```

I'll remove samples that contain the word genome (surely those are not in the face files), the word ver (those are controls from the axiom arrays), the word gDNA, as well as those with the name A_103. 
I've also seen that some of those are outliers in some PCs

```{r removing samples}
removed <- dplyr::filter(pca.eigenvec, IID == "A_103" | grepl("^genome", IID) | 
                    grepl("^ver", IID) | grepl("^gDNA", IID)) %>% 
               dplyr::select(contains("ID"))
head(removed)
pca.eigenvec <- dplyr::filter(pca.eigenvec, IID != "A_103" & !grepl("^genome", IID) & 
                         !grepl("^ver", IID) & !grepl("^gDNA", IID))
```

I removed a total of `r nrow(removed)` samples.
We also have some outliers in PC5, and PC10, clear from the plots of their distributions.
Probably there are also in some other lower PCs.

```{r removing outliers, fig.height=4, fig.width=10, message=FALSE}
p1 <- ggplot(pca.eigenvec, aes(PC5)) + geom_histogram()
p2 <- ggplot(pca.eigenvec, aes(PC10)) + geom_histogram()
ggarrange(p1, p2)

pca.eigenvec %>% dplyr::filter(PC5 > 1) %>% dplyr::select(contains("ID"))
pca.eigenvec %>% dplyr::filter(PC10 < -0.5) %>% dplyr::select(contains("ID"))
  
pca.eigenvec <- pca.eigenvec %>% filter(PC5 < 1 & PC10 > -0.5)

```


## Descriptive and exploratory analyses

Some summary stats

```{r summary}
summary(pca.eigenvec[,c(1,2,53)])
```
 
PCA screeplot

```{r screeplot, fig.height=4, fig.width=8} 
barplot(c(as.matrix(pca.eigenval)), names.arg=PCnames, 
       main = "Variances",
       xlab = "Principal Components",
       ylab = "Eigenvalue",
       col = "steelblue")
```

Looking at the HapMap populations: 

|POP | Description                 
|----|-----------------------------------------------------------------
|ASW | African ancestry in Southwest USA
|CEU | Utah residents with Northern and Western European ancestry from the CEPH collection
|CHB | Han Chinese in Beijing, China
|CHD | Chinese in Metropolitan Denver, Colorado
|GIH | Gujarati Indians in Houston, Texas
|JPT | Japanese in Tokyo, Japan
|LWK | Luhya in Webuye, Kenya
|MXL | Mexican ancestry in Los Angeles, California
|MKK | Maasai in Kinyawa, Kenya
|TSI | Toscani in Italia
|YRI | Yoruba in Ibadan, Nigeria 

```{r hapmap}
plothap <- function(dat, x1, y1)
{
  p1 <- ggplot(dat, aes_string(x = x1, y = y1, color = "database")) +
            geom_point(alpha = 0.3, size = 2) + theme_pubr()
  p1 <- ggpar(p1, palette = "jama")
  return(p1)
}

p1 <- plothap(filter(pca.eigenvec, database != "ADAPT"), "PC1", "PC2")
p2 <- plothap(filter(pca.eigenvec, database != "ADAPT"), "PC3", "PC4")
p3 <- plothap(filter(pca.eigenvec, database != "ADAPT"), "PC5", "PC6")
p4 <- plothap(filter(pca.eigenvec, database != "ADAPT"), "PC7", "PC8")
p5 <- plothap(filter(pca.eigenvec, database != "ADAPT"), "PC9", "PC10")
p6 <- plothap(filter(pca.eigenvec, database != "ADAPT"), "PC11", "PC12")

ggarrange(p1, p2, p3, p4, p5, p6, nrow = 3, ncol = 2,
          common.legend = TRUE, legend = "right", 
          align = "v")
```

We can plot our samples with the centroid of the HapMap pops indicated.

```{r hapmap plus adapt}
meanshap <- dplyr::filter(pca.eigenvec, database != "ADAPT") %>% dplyr::group_by(database) %>% 
            dplyr::select(contains("PC")) %>% summarise_all(funs(mean))

plothapsamp <- function(dat1, dat2, x1, y1)
{
  p1 <- ggplot(dat1, aes_string(x = x1, y = y1, label = "database")) + 
          geom_point(data = dat2, 
                     aes_string(x = x1, y = y1), alpha = 0.3) + 
          geom_label(aes(fill = database), colour = "white", fontface = "bold", alpha = 0.4) + 
          theme_pubr(legend = "none")
  p1 <- ggpar(p1, palette = "jama")
  return(p1)
}
  
p1 <- plothapsamp(meanshap, filter(pca.eigenvec, database == "ADAPT"), "PC1", "PC2")
p2 <- plothapsamp(meanshap, filter(pca.eigenvec, database == "ADAPT"), "PC3", "PC4")
p3 <- plothapsamp(meanshap, filter(pca.eigenvec, database == "ADAPT"), "PC5", "PC6")
p4 <- plothapsamp(meanshap, filter(pca.eigenvec, database == "ADAPT"), "PC7", "PC8")
p5 <- plothapsamp(meanshap, filter(pca.eigenvec, database == "ADAPT"), "PC9", "PC10")
p6 <- plothapsamp(meanshap, filter(pca.eigenvec, database == "ADAPT"), "PC11", "PC12")

ggarrange(p1, p2, p3, p4, p5, p6,
          nrow = 3, ncol = 2,
          align = "v")
```

We can also plot our Irish, Polish, Italian, and Portuguese samples.
Clearly there is a north-south structure in Europe, capture aslso by our samples.

```{r samples w/pop}
plothapgroup <- function(dat1, dat2, x1, y1)
{
  p1 <- ggplot(dat1, aes_string(x = x1, y = y1, label = "database")) + 
          geom_point(data = dat2, aes_string(x = x1, y = y1, color = "FID"), alpha = 0.5) + 
          geom_label(aes(fill = database), colour = "white", fontface = "bold", alpha = 0.5) +
          theme_pubr()
  p1 <- ggpar(p1, palette = "jama")
  return(p1)
}

eurhap  <- filter(meanshap, database == "CEU" | database == "TSI")
eursamp <- filter(pca.eigenvec, FID == "Italian" | FID == "Polish" | FID == "Irish" | 
                            FID == "Portuguese")

p1 <- plothapgroup(eurhap, eursamp, "PC1", "PC2")
p2 <- plothapgroup(eurhap, eursamp, "PC3", "PC4")
p3 <- plothapgroup(eurhap, eursamp, "PC5", "PC6")
p4 <- plothapgroup(eurhap, eursamp, "PC7", "PC8")
p5 <- plothapgroup(eurhap, eursamp, "PC9", "PC10")
p6 <- plothapgroup(eurhap, eursamp, "PC11", "PC12")


ggarrange(p1, p2, p3, p4, p5, p6,
          nrow = 3, ncol = 2,
          common.legend = TRUE, legend = "right",
          align = "v")
```

## Clustering

For an initial clustering attempt I'll group the HapMap populations into continents, as shown in the table:

POP | Continent 
----|------------
ASW | Africa
CEU | Europe
CHB | Asia
CHD | Asia
GIH | SouthAsia
JPT | Asia
LWK | Africa
MXL | American
MKK | Africa
TSI | Europe
YRI | Africa 

```{r continent}
pca.eigenvec$continent[(pca.eigenvec$database == "CEU" | pca.eigenvec$database == "TSI")] <- "Europe"

pca.eigenvec$continent[(pca.eigenvec$database == "ASW" | pca.eigenvec$database == "LWK" |
                        pca.eigenvec$database == "MKK" | pca.eigenvec$database == "YRI")] <- "Africa"

pca.eigenvec$continent[(pca.eigenvec$database == "CHB" | pca.eigenvec$database == "CHD" |
                        pca.eigenvec$database == "JPT")]                                  <- "Asia"

pca.eigenvec$continent[pca.eigenvec$database == "MEX"] <- "America"
pca.eigenvec$continent[pca.eigenvec$database == "GIH"] <- "SouthAsia"
```

If we look at scatter plots of the HapMap samples with the continent variable.

```{r continent plots, fig.height=8}
plotcont <- function(dat, x1, y1)
{
  p1 <- ggplot(dat, aes_string(x = x1, y = y1, color = "continent")) +
            geom_point(alpha = 0.3, size = 2) + theme_pubr()
  p1 <- ggpar(p1, palette = "jama")
  return(p1)
}

p1 <- plotcont(filter(pca.eigenvec, database != "ADAPT"), "PC1", "PC2")
p2 <- plotcont(filter(pca.eigenvec, database != "ADAPT"), "PC3", "PC4")
p3 <- plotcont(filter(pca.eigenvec, database != "ADAPT"), "PC5", "PC6")
p4 <- plotcont(filter(pca.eigenvec, database != "ADAPT"), "PC7", "PC8")

ggarrange(p1, p2, p3, p4, nrow = 2, ncol = 2,
          common.legend = TRUE, legend = "right", 
          align = "v")
```

I'll use the HapMap samples as training, with a 5-fold cross-validation, and predict the values of our samples.

```{r SVM clustering continent, message=FALSE}
set.seed(10)
train <- pca.eigenvec %>% filter(database != "ADAPT")
test  <- pca.eigenvec %>% filter(database == "ADAPT") 

# 5-fold repeated cross-validation
fitControl <- trainControl(method = "repeatedcv", number = 5, repeats = 5)
svm.fit    <- train(continent ~ PC1 + PC2 + PC3 + PC4 + PC5, method = 'svmRadial', 
                     trControl = fitControl, data = train)

svm.fit
test$continent <- predict(svm.fit, test)
summary(test$continent)
```

Scatter plots of the predicted continent groups 

```{r prediceted plots, fig.height=8}
p1 <- plotcont(test, "PC1", "PC2")
p2 <- plotcont(test, "PC3", "PC4")
p3 <- plotcont(test, "PC5", "PC6")
p4 <- plotcont(test, "PC7", "PC8")

ggarrange(p1, p2, p3, p4, nrow = 2, ncol = 2,
          common.legend = TRUE, legend = "right", 
          align = "v")
```

The next step will be to create a clustering of suthern versus northern european populations, using CEU and TSI as training sets. 
We'll double check our clustering with the samples that we have population information (Irish, Polish, Italian, and Portuguese).

```{r svm cluster europe}
pca.eigenvec$Eur[pca.eigenvec$database == "CEU"] <- "NEruope"
pca.eigenvec$Eur[pca.eigenvec$database == "TSI"] <- "SEruope"

set.seed(10)
train.eur <- pca.eigenvec %>% filter(database == "CEU" | database == "TSI")
test.eur  <- filter(test, continent == "Europe")

# 5-fold repeated cross-validation
fitControl  <- trainControl(method = "repeatedcv", number = 5, repeats = 5)
svm.fit.eur <- train(Eur ~ PC1 + PC2 + PC3 + PC4 + PC5, method = 'svmRadial', 
                     trControl = fitControl, data = train.eur)
svm.fit.eur
test.eur$continent <- predict(svm.fit.eur, test.eur)
summary(test.eur$continent)
```

```{r Eur predicted plots, fig.height=8}
p1 <- plotcont(test.eur, "PC1", "PC2")
p2 <- plotcont(test.eur, "PC3", "PC4")
p3 <- plotcont(test.eur, "PC5", "PC6")
p4 <- plotcont(test.eur, "PC7", "PC8")

ggarrange(p1, p2, p3, p4, nrow = 2, ncol = 2,
          common.legend = TRUE, legend = "right", 
          align = "v")
```

```{r merging predictions}
levels(test$continent) <- c("Africa", "America", "Asia", "Europe", "SouthAsia", "NEruope", "SEruope")
test[test$continent == 'Europe', 54] <- test.eur$continent
test$Eur <- NULL
test <- droplevels(test)
summary(test$continent)
```

## Combining datasets

```{r read facedata, message=FALSE, warning=FALSE}
setwd('..')
path <- getwd()
setwd(paste(path, "/Results/PCA", sep = ""))
coeffs   <- read.csv("coeffs.csv")
```

```{r merging}
colnames(coeffs)[1] <- "IID"
total      <- merge(test, coeffs, by = "IID") 
FacePCA    <- total[,59:145]
GenPCA     <- total[,3:52]
Covariates <- total[,c(1,2,55:58,54)]

PCnames <- sprintf("PC%s",seq(1:87))
colnames(FacePCA) <- PCnames

PCnames <- sprintf("PC%s",seq(1:50))
colnames(GenPCA) <- PCnames

MergedDat <- list(Covariates, FacePCA, GenPCA) 

setwd('..')
path <- getwd()
setwd(paste(path, "/Results/MergedData", sep = ""))
save(MergedDat, file = "MergedDat.RData")
```